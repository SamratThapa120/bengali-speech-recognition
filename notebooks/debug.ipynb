{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio, display\n",
    "import plotly.express as px\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"arijitx/wav2vec2-xls-r-300m-bengali\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wav2Vec2Processor:\n",
       "- feature_extractor: Wav2Vec2FeatureExtractor {\n",
       "  \"do_normalize\": true,\n",
       "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
       "  \"feature_size\": 1,\n",
       "  \"padding_side\": \"right\",\n",
       "  \"padding_value\": 0,\n",
       "  \"processor_class\": \"Wav2Vec2ProcessorWithLM\",\n",
       "  \"return_attention_mask\": true,\n",
       "  \"sampling_rate\": 16000\n",
       "}\n",
       "\n",
       "- tokenizer: Wav2Vec2CTCTokenizer(name_or_path='arijitx/wav2vec2-xls-r-300m-bengali', vocab_size=110, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '[UNK]', 'pad_token': '[PAD]', 'additional_special_tokens': [AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True)]}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\"\n",
    "\n",
    "import glob\n",
    "import torch\n",
    "import matplotlib.pyplot as pltm\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of train: 989602, length of valid: 2369\n"
     ]
    }
   ],
   "source": [
    "from configs.whisper_characterwise_pretrained_augs_small_openasr_concataug import Configs\n",
    "CFG = Configs()\n",
    "CFG.load_state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model checkpoints found,loading whisper checkpoint\n",
      "Ignored keys from the checkpoint:\n",
      "\n",
      "Keys with size mismatch:\n",
      "decoder.token_embedding.weight\n",
      "Using collate function..\n",
      "Autoregressive inference: True\n"
     ]
    }
   ],
   "source": [
    "from trainer.whisper_fintune_trainer import Trainer\n",
    "CFG.DISTRIBUTED = False\n",
    "tn = Trainer(CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dloader = iter(tn.train_loader)\n",
    "z = next(dloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12, 80, 315]), torch.Size([12, 35]), torch.Size([12, 35]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[0].shape,z[1].shape,z[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB = {}\n",
    "for v in CFG.training_data.sentence:\n",
    "    for i in v:\n",
    "        if i not in VOCAB:\n",
    "            VOCAB[i]=0\n",
    "        VOCAB[i]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer.wav2vec2_fintune_ctc_trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freezing encoder layer....\n",
      "Using collate function..\n",
      "Autoregressive inference: False\n"
     ]
    }
   ],
   "source": [
    "CFG.DISTRIBUTED=False\n",
    "train = Trainer(CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = iter(train.train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def hook_fn(module, input, output):\n",
    "#     # Check if output has NaN\n",
    "#     if torch.isnan(output if type(output) is not tuple else output[0]).any():\n",
    "#         i = input if type(input) is not tuple else input[0] \n",
    "#         print(f\"NaN detected in layer: {module}, {i.dtype}\")\n",
    "\n",
    "\n",
    "# # Attach hook to each layer of the model\n",
    "# def register_hooks(model):\n",
    "#     for layer in model.children():\n",
    "#         layer.register_forward_hook(hook_fn)\n",
    "#         # Recursively attach hooks to child modules (if any)\n",
    "#         register_hooks(layer)\n",
    "# register_hooks(CFG.model.decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.0314e+00,  1.5075e+01,  2.3425e+01,  ..., -2.4114e+01,\n",
       "           7.1811e+02, -7.6288e+00],\n",
       "         [-5.6977e+01, -1.6832e+01,  2.1679e+01,  ...,  6.9561e+00,\n",
       "           7.6605e+00, -6.3598e+01],\n",
       "         [ 8.5729e+02,  6.2141e+01, -4.1696e+01,  ..., -2.1628e+01,\n",
       "           1.6159e+01, -1.2867e+01],\n",
       "         ...,\n",
       "         [ 1.8641e+01,  5.2420e+01,  4.0240e+01,  ..., -1.9979e+01,\n",
       "          -3.7469e+00,  7.8768e+02],\n",
       "         [ 1.8725e+01,  5.0133e+01,  3.9324e+01,  ..., -1.8752e+01,\n",
       "          -3.1854e+00,  7.8618e+02],\n",
       "         [ 1.8994e+01,  5.1450e+01,  3.8759e+01,  ..., -1.8991e+01,\n",
       "          -4.0456e+00,  7.8531e+02]],\n",
       "\n",
       "        [[-2.7813e+00,  1.5405e+01,  2.3538e+01,  ..., -2.4422e+01,\n",
       "           7.1790e+02, -7.2925e+00],\n",
       "         [-3.6996e+01,  2.8463e+01,  6.6646e+01,  ..., -1.2842e+01,\n",
       "           7.2116e+01, -4.0349e+00],\n",
       "         [ 5.0165e+01, -3.7805e+01,  2.0916e+00,  ...,  3.7272e+01,\n",
       "           3.5184e+01, -9.2115e+00],\n",
       "         ...,\n",
       "         [ 1.4836e+01,  5.6576e+01,  4.0122e+01,  ..., -2.0095e+01,\n",
       "          -3.8040e+00,  8.0804e+02],\n",
       "         [ 1.4955e+01,  5.4305e+01,  3.9161e+01,  ..., -1.8813e+01,\n",
       "          -3.2580e+00,  8.0639e+02],\n",
       "         [ 1.5186e+01,  5.5526e+01,  3.8548e+01,  ..., -1.9038e+01,\n",
       "          -4.0809e+00,  8.0544e+02]],\n",
       "\n",
       "        [[-3.1732e+00,  1.4642e+01,  2.3829e+01,  ..., -2.3636e+01,\n",
       "           7.1853e+02, -7.7644e+00],\n",
       "         [-2.5239e+01,  4.4190e+00,  3.8734e+01,  ...,  5.8730e+01,\n",
       "           1.0991e+01, -4.6373e+01],\n",
       "         [-3.7695e+01,  2.6901e+01,  1.0801e+01,  ...,  2.0476e-01,\n",
       "           9.5253e-01, -1.6506e+01],\n",
       "         ...,\n",
       "         [ 1.5718e+01,  5.2235e+01,  4.2250e+01,  ..., -1.9260e+01,\n",
       "          -6.6217e-01,  8.2847e+02],\n",
       "         [ 1.5833e+01,  4.9900e+01,  4.1373e+01,  ..., -1.7793e+01,\n",
       "          -4.9770e-02,  8.2679e+02],\n",
       "         [ 1.6146e+01,  5.1269e+01,  4.0699e+01,  ..., -1.7991e+01,\n",
       "          -9.0024e-01,  8.2568e+02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-3.5976e+00,  1.4496e+01,  2.3970e+01,  ..., -2.3516e+01,\n",
       "           7.1829e+02, -9.0287e+00],\n",
       "         [-3.7330e+01,  1.3658e+01, -4.9513e+01,  ...,  1.0960e+01,\n",
       "          -7.6058e+00,  1.9464e+01],\n",
       "         [ 4.6538e+01,  8.4802e+02, -3.2955e+00,  ...,  4.9946e+00,\n",
       "           1.1828e+01, -2.4872e+01],\n",
       "         ...,\n",
       "         [ 1.2319e+01,  4.4574e+01,  4.2460e+01,  ..., -1.7395e+01,\n",
       "          -2.0218e+00,  8.6145e+02],\n",
       "         [ 1.2435e+01,  4.2365e+01,  4.1509e+01,  ..., -1.5955e+01,\n",
       "          -1.3500e+00,  8.5986e+02],\n",
       "         [ 1.2770e+01,  4.3876e+01,  4.0748e+01,  ..., -1.6004e+01,\n",
       "          -2.1952e+00,  8.5837e+02]],\n",
       "\n",
       "        [[-3.3628e+00,  1.5690e+01,  2.3618e+01,  ..., -2.3828e+01,\n",
       "           7.1824e+02, -7.7573e+00],\n",
       "         [-8.2181e+00,  5.1094e+01,  2.2555e+01,  ...,  8.4594e+00,\n",
       "           3.8118e+01, -4.2945e+01],\n",
       "         [-1.9526e+01,  1.0450e+01,  2.8892e+01,  ..., -1.5067e+01,\n",
       "           7.1370e+00, -3.3159e+01],\n",
       "         ...,\n",
       "         [ 1.4869e+01,  5.0022e+01,  4.3773e+01,  ..., -1.7266e+01,\n",
       "          -2.7755e+00,  8.3552e+02],\n",
       "         [ 1.5019e+01,  4.7729e+01,  4.2820e+01,  ..., -1.5825e+01,\n",
       "          -2.1953e+00,  8.3396e+02],\n",
       "         [ 1.5298e+01,  4.9176e+01,  4.2046e+01,  ..., -1.6061e+01,\n",
       "          -2.9695e+00,  8.3272e+02]],\n",
       "\n",
       "        [[-3.5642e+00,  1.5474e+01,  2.4167e+01,  ..., -2.3744e+01,\n",
       "           7.1778e+02, -7.6721e+00],\n",
       "         [-8.2037e+00,  5.1048e+01,  2.2964e+01,  ...,  8.5147e+00,\n",
       "           3.7016e+01, -4.2931e+01],\n",
       "         [-1.9737e+01,  1.0420e+01,  2.9588e+01,  ..., -1.4846e+01,\n",
       "           6.0139e+00, -3.2897e+01],\n",
       "         ...,\n",
       "         [ 1.7548e+01,  4.8886e+01,  4.5336e+01,  ..., -1.8756e+01,\n",
       "           5.6556e-01,  8.1630e+02],\n",
       "         [ 1.7665e+01,  4.6612e+01,  4.4408e+01,  ..., -1.7360e+01,\n",
       "           1.1273e+00,  8.1464e+02],\n",
       "         [ 1.7929e+01,  4.7972e+01,  4.3665e+01,  ..., -1.7622e+01,\n",
       "           2.3921e-01,  8.1363e+02]]], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = next(loader)\n",
    "[tt.shape for tt in z]\n",
    "[tt.dtype for tt in z]\n",
    "with torch.no_grad():\n",
    "    pred1 =  CFG.model.encoder(z[0].cuda().float())\n",
    "    pred = CFG.model(z[0].cuda().float(),z[1].cuda().long())\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
